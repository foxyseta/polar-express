{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Polar Express\n",
        "\n",
        "Stefano Volpe #0000969766\n",
        "\n",
        "University of Bologna\n",
        "\n",
        "Introduction to Machine Learning\n",
        "\n",
        "a.y. 2022/23"
      ],
      "metadata": {
        "id": "iLddMBwtQMuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "_SRQhd93Qf_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.activations import elu, gelu, relu, sigmoid, softmax, softsign, \\\n",
        "  swish, tanh\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Concatenate, Dense, Input, Normalization\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Nadam\n",
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "Ix4yJ9OVq4ka"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator"
      ],
      "metadata": {
        "id": "93Bz50lEQWpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def polar_generator(batchsize, grid = (10, 10), noise = .002, flat = False):\n",
        "  while True:\n",
        "    x = np.random.rand(batchsize)\n",
        "    y = np.random.rand(batchsize)\n",
        "    out = np.zeros((batchsize, grid[0], grid[1]))\n",
        "    xc = (x * grid[0]).astype(int)\n",
        "    yc = (y * grid[1]).astype(int)\n",
        "    for b in range(batchsize):\n",
        "      out[b,xc[b],yc[b]] = 1\n",
        "    # compute rho and theta and add some noise\n",
        "    rho = np.sqrt(x ** 2 + y ** 2) + np.random.normal(scale = noise)\n",
        "    theta = np.arctan(y / np.maximum(x, .00001)) + \\\n",
        "      np.random.normal(scale = noise)\n",
        "    if flat:\n",
        "      out = np.reshape(out, (batchsize, grid[0]*grid[1]))\n",
        "    yield ((theta,rho),out)"
      ],
      "metadata": {
        "id": "2NyUrOH2QKwJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "The project requirements ask for a size of the validation greater or equal than 20000. In order for it to be one fourth of the training set (which is a good rule of thumb in general), 500000 was chosen. "
      ],
      "metadata": {
        "id": "d1sXdTaZQ5NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set_size, validation_set_size = 2000000, 500000\n",
        "\n",
        "(training_theta, training_rho), training_maps = next(polar_generator(training_set_size, flat = True))\n",
        "(validation_theta, validation_rho), validation_maps = next(polar_generator(training_set_size, flat = True))"
      ],
      "metadata": {
        "id": "C0_hDTg0Q94c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics\n",
        "\n",
        "The project requirements ask to compute the categorical accuracy of your model on your own, rather than using Keras's implementation."
      ],
      "metadata": {
        "id": "cMb0itb9UOQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def argmax_axis_1(input: tf.Tensor) -> int:\n",
        "  return tf.argmax(input, axis = 1)\n",
        "\n",
        "def my_categorical_accuracy(y_true : tf.Tensor, y_pred : tf.Tensor) -> tf.float64:\n",
        "  # The right categories (according to our ground truth)\n",
        "  y_true_argmax = argmax_axis_1(y_true)\n",
        "  # The predictions our model assert with the most confidence\n",
        "  y_pred_argmax = argmax_axis_1(y_pred)\n",
        "  # Element-wise equality\n",
        "  equalities = tf.equal(y_true_argmax, y_pred_argmax)\n",
        "  # Since True converts to 1.0, accuracy and arithmetic mean are\n",
        "  # equivalent\n",
        "  equalities = tf.cast(equalities, tf.float64)\n",
        "  return tf.reduce_mean(equalities)"
      ],
      "metadata": {
        "id": "cIA03P1QsN0k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "MaEiD0dGVsoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_set_size = 10000\n",
        "\n",
        "def makeNetwork() -> Model:\n",
        "  theta = Input(shape = (1, ), name = \"Theta\")\n",
        "  theta_normalization = Normalization(axis = None, name = \"ThetaNormalization\")\n",
        "  theta_normalization.adapt(training_theta[:normalization_set_size])\n",
        "  theta_normalization = theta_normalization(theta)\n",
        "  a1 = Dense(2, activation = softsign, name = \"A1\")(theta_normalization)\n",
        "  a2 = Dense(4, activation = tanh, name = \"A2\")(a1)\n",
        "  a3 = Dense(4, activation = sigmoid, name = \"A3\")(a2)\n",
        "\n",
        "  rho = Input(shape = (1,), name = \"Rho\")\n",
        "  rho_normalization = Normalization(axis = None, name = \"RhoNormalization\")\n",
        "  rho_normalization.adapt(training_rho[:normalization_set_size])\n",
        "  rho_normalization = rho_normalization(rho)\n",
        "  b1 = Dense(4, activation = softsign, name = \"B1\")(rho_normalization)\n",
        "\n",
        "  ab1 = Concatenate(name = \"AB1\")([a3, rho_normalization])\n",
        "  ab2 = Dense(8, activation = swish, name = \"AB2\")(ab1)\n",
        "  ab3 = Dense(8, activation = relu, name = \"AB3\")(ab2)\n",
        "  ab4 = Dense(3, activation = gelu, name = \"AB4\")(ab3)\n",
        "  out = Dense(100, activation = softmax, name = \"out\")(ab4)\n",
        "  return Model([theta, rho], out)\n",
        "\n",
        "polar_express = makeNetwork()\n",
        "polar_express.build((None, 2))\n",
        "polar_express.summary(show_trainable = False)\n",
        "plot_model(\n",
        "  polar_express,\n",
        "  show_shapes = True,\n",
        "  show_dtype = True,\n",
        "  show_layer_activations = True,\n",
        ")\n",
        "polar_express.compile(\n",
        "  Nadam(),\n",
        "  CategoricalCrossentropy(),\n",
        "  metrics = [my_categorical_accuracy]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiKzWgkAsevu",
        "outputId": "736d1b96-af3c-4fe7-8a71-0e36820e477f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Theta (InputLayer)             [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " ThetaNormalization (Normalizat  (None, 1)           3           ['Theta[0][0]']                  \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " A1 (Dense)                     (None, 2)            4           ['ThetaNormalization[0][0]']     \n",
            "                                                                                                  \n",
            " A2 (Dense)                     (None, 4)            12          ['A1[0][0]']                     \n",
            "                                                                                                  \n",
            " Rho (InputLayer)               [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " A3 (Dense)                     (None, 4)            20          ['A2[0][0]']                     \n",
            "                                                                                                  \n",
            " RhoNormalization (Normalizatio  (None, 1)           3           ['Rho[0][0]']                    \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " AB1 (Concatenate)              (None, 5)            0           ['A3[0][0]',                     \n",
            "                                                                  'RhoNormalization[0][0]']       \n",
            "                                                                                                  \n",
            " AB2 (Dense)                    (None, 8)            48          ['AB1[0][0]']                    \n",
            "                                                                                                  \n",
            " AB3 (Dense)                    (None, 8)            72          ['AB2[0][0]']                    \n",
            "                                                                                                  \n",
            " AB4 (Dense)                    (None, 3)            27          ['AB3[0][0]']                    \n",
            "                                                                                                  \n",
            " out (Dense)                    (None, 100)          400         ['AB4[0][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 589\n",
            "Trainable params: 583\n",
            "Non-trainable params: 6\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and evaluation\n",
        "\n",
        "Here is the training history. For each epoch, the network has been evaluated via\n",
        "categorical accuracy on the validation set (see `val_my_categorical_accuracy`)."
      ],
      "metadata": {
        "id": "cWDtZr8fZw95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4096\n",
        "epochs = 99\n",
        "verbose = 2\n",
        "\n",
        "polar_express.fit(\n",
        "  (training_theta, training_rho),\n",
        "  training_maps,\n",
        "  batch_size,\n",
        "  epochs,\n",
        "  verbose,\n",
        "  [EarlyStopping(monitor = 'val_loss', patience = 4)],\n",
        "  validation_data = ((validation_theta, validation_rho), validation_maps)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnRfV1eQtDNe",
        "outputId": "1618613f-c8c8-4ba6-f4a4-62ac58380cb0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/99\n",
            "489/489 - 7s - loss: 3.8001 - my_categorical_accuracy: 0.0472 - val_loss: 2.8037 - val_my_categorical_accuracy: 0.1315 - 7s/epoch - 14ms/step\n",
            "Epoch 2/99\n",
            "489/489 - 5s - loss: 2.4514 - my_categorical_accuracy: 0.1849 - val_loss: 2.2448 - val_my_categorical_accuracy: 0.2215 - 5s/epoch - 11ms/step\n",
            "Epoch 3/99\n",
            "489/489 - 4s - loss: 2.0602 - my_categorical_accuracy: 0.2648 - val_loss: 1.8933 - val_my_categorical_accuracy: 0.2889 - 4s/epoch - 9ms/step\n",
            "Epoch 4/99\n",
            "489/489 - 4s - loss: 1.5978 - my_categorical_accuracy: 0.4106 - val_loss: 1.2499 - val_my_categorical_accuracy: 0.5257 - 4s/epoch - 9ms/step\n",
            "Epoch 5/99\n",
            "489/489 - 5s - loss: 0.9158 - my_categorical_accuracy: 0.7004 - val_loss: 0.7151 - val_my_categorical_accuracy: 0.7668 - 5s/epoch - 11ms/step\n",
            "Epoch 6/99\n",
            "489/489 - 4s - loss: 0.6010 - my_categorical_accuracy: 0.8273 - val_loss: 0.5331 - val_my_categorical_accuracy: 0.8389 - 4s/epoch - 9ms/step\n",
            "Epoch 7/99\n",
            "489/489 - 4s - loss: 0.4761 - my_categorical_accuracy: 0.8645 - val_loss: 0.4549 - val_my_categorical_accuracy: 0.8560 - 4s/epoch - 8ms/step\n",
            "Epoch 8/99\n",
            "489/489 - 5s - loss: 0.4068 - my_categorical_accuracy: 0.8815 - val_loss: 0.3980 - val_my_categorical_accuracy: 0.8687 - 5s/epoch - 11ms/step\n",
            "Epoch 9/99\n",
            "489/489 - 4s - loss: 0.3592 - my_categorical_accuracy: 0.8940 - val_loss: 0.3562 - val_my_categorical_accuracy: 0.8823 - 4s/epoch - 9ms/step\n",
            "Epoch 10/99\n",
            "489/489 - 5s - loss: 0.3230 - my_categorical_accuracy: 0.9044 - val_loss: 0.3227 - val_my_categorical_accuracy: 0.8952 - 5s/epoch - 11ms/step\n",
            "Epoch 11/99\n",
            "489/489 - 5s - loss: 0.2937 - my_categorical_accuracy: 0.9133 - val_loss: 0.2959 - val_my_categorical_accuracy: 0.9017 - 5s/epoch - 11ms/step\n",
            "Epoch 12/99\n",
            "489/489 - 5s - loss: 0.2695 - my_categorical_accuracy: 0.9210 - val_loss: 0.2748 - val_my_categorical_accuracy: 0.9091 - 5s/epoch - 11ms/step\n",
            "Epoch 13/99\n",
            "489/489 - 5s - loss: 0.2490 - my_categorical_accuracy: 0.9280 - val_loss: 0.2542 - val_my_categorical_accuracy: 0.9154 - 5s/epoch - 11ms/step\n",
            "Epoch 14/99\n",
            "489/489 - 5s - loss: 0.2316 - my_categorical_accuracy: 0.9343 - val_loss: 0.2386 - val_my_categorical_accuracy: 0.9209 - 5s/epoch - 11ms/step\n",
            "Epoch 15/99\n",
            "489/489 - 5s - loss: 0.2167 - my_categorical_accuracy: 0.9396 - val_loss: 0.2240 - val_my_categorical_accuracy: 0.9276 - 5s/epoch - 11ms/step\n",
            "Epoch 16/99\n",
            "489/489 - 4s - loss: 0.2039 - my_categorical_accuracy: 0.9445 - val_loss: 0.2177 - val_my_categorical_accuracy: 0.9272 - 4s/epoch - 9ms/step\n",
            "Epoch 17/99\n",
            "489/489 - 4s - loss: 0.1926 - my_categorical_accuracy: 0.9487 - val_loss: 0.2156 - val_my_categorical_accuracy: 0.9216 - 4s/epoch - 9ms/step\n",
            "Epoch 18/99\n",
            "489/489 - 4s - loss: 0.1829 - my_categorical_accuracy: 0.9520 - val_loss: 0.1927 - val_my_categorical_accuracy: 0.9372 - 4s/epoch - 9ms/step\n",
            "Epoch 19/99\n",
            "489/489 - 4s - loss: 0.1740 - my_categorical_accuracy: 0.9553 - val_loss: 0.1968 - val_my_categorical_accuracy: 0.9288 - 4s/epoch - 9ms/step\n",
            "Epoch 20/99\n",
            "489/489 - 5s - loss: 0.1664 - my_categorical_accuracy: 0.9578 - val_loss: 0.1805 - val_my_categorical_accuracy: 0.9388 - 5s/epoch - 11ms/step\n",
            "Epoch 21/99\n",
            "489/489 - 5s - loss: 0.1594 - my_categorical_accuracy: 0.9600 - val_loss: 0.1679 - val_my_categorical_accuracy: 0.9463 - 5s/epoch - 11ms/step\n",
            "Epoch 22/99\n",
            "489/489 - 5s - loss: 0.1532 - my_categorical_accuracy: 0.9620 - val_loss: 0.1661 - val_my_categorical_accuracy: 0.9440 - 5s/epoch - 10ms/step\n",
            "Epoch 23/99\n",
            "489/489 - 5s - loss: 0.1475 - my_categorical_accuracy: 0.9639 - val_loss: 0.1552 - val_my_categorical_accuracy: 0.9520 - 5s/epoch - 11ms/step\n",
            "Epoch 24/99\n",
            "489/489 - 4s - loss: 0.1423 - my_categorical_accuracy: 0.9654 - val_loss: 0.1554 - val_my_categorical_accuracy: 0.9480 - 4s/epoch - 9ms/step\n",
            "Epoch 25/99\n",
            "489/489 - 4s - loss: 0.1377 - my_categorical_accuracy: 0.9665 - val_loss: 0.1512 - val_my_categorical_accuracy: 0.9488 - 4s/epoch - 9ms/step\n",
            "Epoch 26/99\n",
            "489/489 - 5s - loss: 0.1334 - my_categorical_accuracy: 0.9677 - val_loss: 0.1471 - val_my_categorical_accuracy: 0.9515 - 5s/epoch - 11ms/step\n",
            "Epoch 27/99\n",
            "489/489 - 5s - loss: 0.1295 - my_categorical_accuracy: 0.9686 - val_loss: 0.1419 - val_my_categorical_accuracy: 0.9517 - 5s/epoch - 11ms/step\n",
            "Epoch 28/99\n",
            "489/489 - 4s - loss: 0.1257 - my_categorical_accuracy: 0.9697 - val_loss: 0.1642 - val_my_categorical_accuracy: 0.9329 - 4s/epoch - 9ms/step\n",
            "Epoch 29/99\n",
            "489/489 - 5s - loss: 0.1224 - my_categorical_accuracy: 0.9704 - val_loss: 0.1326 - val_my_categorical_accuracy: 0.9563 - 5s/epoch - 11ms/step\n",
            "Epoch 30/99\n",
            "489/489 - 5s - loss: 0.1193 - my_categorical_accuracy: 0.9711 - val_loss: 0.1419 - val_my_categorical_accuracy: 0.9461 - 5s/epoch - 11ms/step\n",
            "Epoch 31/99\n",
            "489/489 - 4s - loss: 0.1164 - my_categorical_accuracy: 0.9717 - val_loss: 0.1330 - val_my_categorical_accuracy: 0.9521 - 4s/epoch - 9ms/step\n",
            "Epoch 32/99\n",
            "489/489 - 4s - loss: 0.1137 - my_categorical_accuracy: 0.9725 - val_loss: 0.1247 - val_my_categorical_accuracy: 0.9583 - 4s/epoch - 9ms/step\n",
            "Epoch 33/99\n",
            "489/489 - 4s - loss: 0.1112 - my_categorical_accuracy: 0.9729 - val_loss: 0.1202 - val_my_categorical_accuracy: 0.9610 - 4s/epoch - 9ms/step\n",
            "Epoch 34/99\n",
            "489/489 - 5s - loss: 0.1089 - my_categorical_accuracy: 0.9733 - val_loss: 0.1281 - val_my_categorical_accuracy: 0.9523 - 5s/epoch - 11ms/step\n",
            "Epoch 35/99\n",
            "489/489 - 4s - loss: 0.1066 - my_categorical_accuracy: 0.9737 - val_loss: 0.1250 - val_my_categorical_accuracy: 0.9539 - 4s/epoch - 8ms/step\n",
            "Epoch 36/99\n",
            "489/489 - 5s - loss: 0.1046 - my_categorical_accuracy: 0.9743 - val_loss: 0.1326 - val_my_categorical_accuracy: 0.9464 - 5s/epoch - 11ms/step\n",
            "Epoch 37/99\n",
            "489/489 - 5s - loss: 0.1027 - my_categorical_accuracy: 0.9747 - val_loss: 0.1266 - val_my_categorical_accuracy: 0.9513 - 5s/epoch - 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb4f06f01c0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_SRQhd93Qf_W",
        "93Bz50lEQWpN",
        "d1sXdTaZQ5NI",
        "cMb0itb9UOQ2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}