{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Polar Express\n",
        "\n",
        "Stefano Volpe #0000969766\n",
        "\n",
        "University of Bologna\n",
        "\n",
        "Introduction to Machine Learning\n",
        "\n",
        "a.y. 2022/23"
      ],
      "metadata": {
        "id": "iLddMBwtQMuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "_SRQhd93Qf_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.activations import elu, gelu, relu, sigmoid, softmax, softsign, \\\n",
        "  swish, tanh\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Concatenate, Dense, Input, Normalization\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Nadam\n",
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "Ix4yJ9OVq4ka"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator"
      ],
      "metadata": {
        "id": "93Bz50lEQWpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def polar_generator(batchsize, grid = (10, 10), noise = .002, flat = False):\n",
        "  while True:\n",
        "    x = np.random.rand(batchsize)\n",
        "    y = np.random.rand(batchsize)\n",
        "    out = np.zeros((batchsize, grid[0], grid[1]))\n",
        "    xc = (x * grid[0]).astype(int)\n",
        "    yc = (y * grid[1]).astype(int)\n",
        "    for b in range(batchsize):\n",
        "      out[b,xc[b],yc[b]] = 1\n",
        "    # compute rho and theta and add some noise\n",
        "    rho = np.sqrt(x ** 2 + y ** 2) + np.random.normal(scale = noise)\n",
        "    theta = np.arctan(y / np.maximum(x, .00001)) + \\\n",
        "      np.random.normal(scale = noise)\n",
        "    if flat:\n",
        "      out = np.reshape(out, (batchsize, grid[0]*grid[1]))\n",
        "    yield ((theta,rho),out)"
      ],
      "metadata": {
        "id": "2NyUrOH2QKwJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "The project requirements ask for a size of the validation greater or equal than 20000. In order for it to be one fourth of the training set (which is a good rule of thumb in general), 1000000 was chosen. "
      ],
      "metadata": {
        "id": "d1sXdTaZQ5NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set_size, validation_set_size = 2000000, 500000\n",
        "\n",
        "(training_theta, training_rho), training_maps = next(polar_generator(training_set_size, flat = True))\n",
        "(validation_theta, validation_rho), validation_maps = next(polar_generator(training_set_size, flat = True))"
      ],
      "metadata": {
        "id": "C0_hDTg0Q94c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics\n",
        "\n",
        "The project requirements ask to compute the categorical accuracy of your model on your own, rather than using Keras's implementation."
      ],
      "metadata": {
        "id": "cMb0itb9UOQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def argmax_axis_1(input: tf.Tensor) -> int:\n",
        "  return tf.argmax(input, axis = 1)\n",
        "\n",
        "def my_categorical_accuracy(y_true : tf.Tensor, y_pred : tf.Tensor) -> tf.float64:\n",
        "  # The right categories (according to our ground truth)\n",
        "  y_true_argmax = argmax_axis_1(y_true)\n",
        "  # The predictions our model assert with the most confidence\n",
        "  y_pred_argmax = argmax_axis_1(y_pred)\n",
        "  # Element-wise equality\n",
        "  equalities = tf.equal(y_true_argmax, y_pred_argmax)\n",
        "  # Since True converts to 1.0, accuracy and arithmetic mean are\n",
        "  # equivalent\n",
        "  equalities = tf.cast(equalities, tf.float64)\n",
        "  return tf.reduce_mean(equalities)"
      ],
      "metadata": {
        "id": "cIA03P1QsN0k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "MaEiD0dGVsoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_set_size = 10000\n",
        "\n",
        "def makeNetwork() -> Model:\n",
        "  theta_input = Input(shape = (1, ))\n",
        "  theta_norm = Normalization(axis = None)\n",
        "  theta_norm.adapt(training_theta[:normalization_set_size])\n",
        "  theta_norm = theta_norm(theta_input)\n",
        "  theta_branch = Dense(2, activation = softsign)(theta_norm)\n",
        "  theta_branch = Dense(4, activation = tanh)(theta_branch)\n",
        "  theta_branch = Dense(4, activation = sigmoid)(theta_branch)\n",
        "\n",
        "  rho_input = Input(shape = (1,))\n",
        "  rho_norm = Normalization(axis = None)\n",
        "  rho_norm.adapt(training_rho[:normalization_set_size])\n",
        "  rho_norm = rho_norm(rho_input)\n",
        "\n",
        "  rho_branch = Dense(4, activation = softsign)(rho_norm)\n",
        "  rho_branch = Dense(4, activation = swish)(rho_branch)\n",
        "  rho_branch = Dense(4, activation = tanh)(rho_branch)\n",
        "  rho_branch = Dense(4, activation = elu)(rho_branch)\n",
        "\n",
        "  concatenate_layer = Concatenate()([theta_branch, rho_branch])\n",
        "  output = Dense(8, activation = swish)(concatenate_layer)\n",
        "  output = Dense(16, activation = relu)(output)\n",
        "  output = Dense(4, activation = gelu)(output)\n",
        "  output = Dense(100, activation = softmax)(output)\n",
        "  return Model([theta_input, rho_input], output)\n",
        "\n",
        "network = makeNetwork()\n",
        "network.build((None, 2))\n",
        "network.summary(show_trainable = False)\n",
        "plot_model(\n",
        "  network,\n",
        "  show_shapes = True,\n",
        "  show_dtype = True,\n",
        "  show_layer_activations = True,\n",
        ")\n",
        "network.compile(\n",
        "  Nadam(),\n",
        "  CategoricalCrossentropy(),\n",
        "  metrics = [my_categorical_accuracy]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiKzWgkAsevu",
        "outputId": "ec8f8ea7-401e-4850-b1fd-2ec81cb2e9bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " normalization_1 (Normalization  (None, 1)           3           ['input_2[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " normalization (Normalization)  (None, 1)            3           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 4)            8           ['normalization_1[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            4           ['normalization[0][0]']          \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 4)            20          ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 4)            12          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 4)            20          ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            20          ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 4)            20          ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8)            0           ['dense_2[0][0]',                \n",
            "                                                                  'dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 8)            72          ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 16)           144         ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 4)            68          ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 100)          500         ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 894\n",
            "Trainable params: 888\n",
            "Non-trainable params: 6\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and evaluation"
      ],
      "metadata": {
        "id": "cWDtZr8fZw95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4096\n",
        "epochs = 150\n",
        "verbose = 2\n",
        "\n",
        "network.fit(\n",
        "  (training_theta, training_rho),\n",
        "  training_maps,\n",
        "  batch_size,\n",
        "  epochs,\n",
        "  verbose,\n",
        "  [EarlyStopping(monitor = 'val_loss', patience = 4)],\n",
        "  validation_data = ((validation_theta, validation_rho), validation_maps)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnRfV1eQtDNe",
        "outputId": "972c8ff9-18d6-4e0f-e937-0329ff02c555"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "489/489 - 10s - loss: 3.6639 - my_categorical_accuracy: 0.0673 - val_loss: 2.6254 - val_my_categorical_accuracy: 0.1915 - 10s/epoch - 21ms/step\n",
            "Epoch 2/150\n",
            "489/489 - 6s - loss: 1.8089 - my_categorical_accuracy: 0.4117 - val_loss: 1.1370 - val_my_categorical_accuracy: 0.6346 - 6s/epoch - 12ms/step\n",
            "Epoch 3/150\n",
            "489/489 - 5s - loss: 0.8405 - my_categorical_accuracy: 0.7609 - val_loss: 0.6778 - val_my_categorical_accuracy: 0.7864 - 5s/epoch - 9ms/step\n",
            "Epoch 4/150\n",
            "489/489 - 5s - loss: 0.5692 - my_categorical_accuracy: 0.8418 - val_loss: 0.5247 - val_my_categorical_accuracy: 0.8315 - 5s/epoch - 9ms/step\n",
            "Epoch 5/150\n",
            "489/489 - 5s - loss: 0.4518 - my_categorical_accuracy: 0.8743 - val_loss: 0.4355 - val_my_categorical_accuracy: 0.8597 - 5s/epoch - 9ms/step\n",
            "Epoch 6/150\n",
            "489/489 - 5s - loss: 0.3815 - my_categorical_accuracy: 0.8935 - val_loss: 0.3702 - val_my_categorical_accuracy: 0.8818 - 5s/epoch - 9ms/step\n",
            "Epoch 7/150\n",
            "489/489 - 5s - loss: 0.3334 - my_categorical_accuracy: 0.9070 - val_loss: 0.3310 - val_my_categorical_accuracy: 0.8932 - 5s/epoch - 9ms/step\n",
            "Epoch 8/150\n",
            "489/489 - 6s - loss: 0.2976 - my_categorical_accuracy: 0.9175 - val_loss: 0.3008 - val_my_categorical_accuracy: 0.9007 - 6s/epoch - 12ms/step\n",
            "Epoch 9/150\n",
            "489/489 - 5s - loss: 0.2694 - my_categorical_accuracy: 0.9261 - val_loss: 0.2821 - val_my_categorical_accuracy: 0.9037 - 5s/epoch - 9ms/step\n",
            "Epoch 10/150\n",
            "489/489 - 5s - loss: 0.2465 - my_categorical_accuracy: 0.9333 - val_loss: 0.2616 - val_my_categorical_accuracy: 0.9097 - 5s/epoch - 9ms/step\n",
            "Epoch 11/150\n",
            "489/489 - 5s - loss: 0.2277 - my_categorical_accuracy: 0.9393 - val_loss: 0.2589 - val_my_categorical_accuracy: 0.9038 - 5s/epoch - 9ms/step\n",
            "Epoch 12/150\n",
            "489/489 - 5s - loss: 0.2121 - my_categorical_accuracy: 0.9443 - val_loss: 0.2349 - val_my_categorical_accuracy: 0.9161 - 5s/epoch - 11ms/step\n",
            "Epoch 13/150\n",
            "489/489 - 5s - loss: 0.1985 - my_categorical_accuracy: 0.9489 - val_loss: 0.2067 - val_my_categorical_accuracy: 0.9342 - 5s/epoch - 9ms/step\n",
            "Epoch 14/150\n",
            "489/489 - 5s - loss: 0.1864 - my_categorical_accuracy: 0.9530 - val_loss: 0.1940 - val_my_categorical_accuracy: 0.9405 - 5s/epoch - 10ms/step\n",
            "Epoch 15/150\n",
            "489/489 - 5s - loss: 0.1761 - my_categorical_accuracy: 0.9563 - val_loss: 0.2149 - val_my_categorical_accuracy: 0.9179 - 5s/epoch - 9ms/step\n",
            "Epoch 16/150\n",
            "489/489 - 6s - loss: 0.1670 - my_categorical_accuracy: 0.9591 - val_loss: 0.1937 - val_my_categorical_accuracy: 0.9294 - 6s/epoch - 13ms/step\n",
            "Epoch 17/150\n",
            "489/489 - 5s - loss: 0.1586 - my_categorical_accuracy: 0.9617 - val_loss: 0.1799 - val_my_categorical_accuracy: 0.9366 - 5s/epoch - 9ms/step\n",
            "Epoch 18/150\n",
            "489/489 - 5s - loss: 0.1513 - my_categorical_accuracy: 0.9639 - val_loss: 0.1674 - val_my_categorical_accuracy: 0.9440 - 5s/epoch - 9ms/step\n",
            "Epoch 19/150\n",
            "489/489 - 6s - loss: 0.1438 - my_categorical_accuracy: 0.9660 - val_loss: 0.1643 - val_my_categorical_accuracy: 0.9417 - 6s/epoch - 12ms/step\n",
            "Epoch 20/150\n",
            "489/489 - 6s - loss: 0.1375 - my_categorical_accuracy: 0.9680 - val_loss: 0.1684 - val_my_categorical_accuracy: 0.9357 - 6s/epoch - 12ms/step\n",
            "Epoch 21/150\n",
            "489/489 - 5s - loss: 0.1328 - my_categorical_accuracy: 0.9687 - val_loss: 0.1556 - val_my_categorical_accuracy: 0.9416 - 5s/epoch - 9ms/step\n",
            "Epoch 22/150\n",
            "489/489 - 5s - loss: 0.1279 - my_categorical_accuracy: 0.9699 - val_loss: 0.1535 - val_my_categorical_accuracy: 0.9439 - 5s/epoch - 9ms/step\n",
            "Epoch 23/150\n",
            "489/489 - 6s - loss: 0.1238 - my_categorical_accuracy: 0.9706 - val_loss: 0.1455 - val_my_categorical_accuracy: 0.9463 - 6s/epoch - 12ms/step\n",
            "Epoch 24/150\n",
            "489/489 - 6s - loss: 0.1198 - my_categorical_accuracy: 0.9718 - val_loss: 0.1398 - val_my_categorical_accuracy: 0.9501 - 6s/epoch - 12ms/step\n",
            "Epoch 25/150\n",
            "489/489 - 5s - loss: 0.1160 - my_categorical_accuracy: 0.9727 - val_loss: 0.1420 - val_my_categorical_accuracy: 0.9453 - 5s/epoch - 9ms/step\n",
            "Epoch 26/150\n",
            "489/489 - 6s - loss: 0.1130 - my_categorical_accuracy: 0.9730 - val_loss: 0.1375 - val_my_categorical_accuracy: 0.9485 - 6s/epoch - 12ms/step\n",
            "Epoch 27/150\n",
            "489/489 - 5s - loss: 0.1099 - my_categorical_accuracy: 0.9736 - val_loss: 0.1513 - val_my_categorical_accuracy: 0.9378 - 5s/epoch - 10ms/step\n",
            "Epoch 28/150\n",
            "489/489 - 5s - loss: 0.1069 - my_categorical_accuracy: 0.9743 - val_loss: 0.1360 - val_my_categorical_accuracy: 0.9469 - 5s/epoch - 9ms/step\n",
            "Epoch 29/150\n",
            "489/489 - 5s - loss: 0.1045 - my_categorical_accuracy: 0.9744 - val_loss: 0.1425 - val_my_categorical_accuracy: 0.9415 - 5s/epoch - 9ms/step\n",
            "Epoch 30/150\n",
            "489/489 - 5s - loss: 0.1018 - my_categorical_accuracy: 0.9752 - val_loss: 0.1500 - val_my_categorical_accuracy: 0.9390 - 5s/epoch - 9ms/step\n",
            "Epoch 31/150\n",
            "489/489 - 6s - loss: 0.0998 - my_categorical_accuracy: 0.9754 - val_loss: 0.1411 - val_my_categorical_accuracy: 0.9420 - 6s/epoch - 12ms/step\n",
            "Epoch 32/150\n",
            "489/489 - 5s - loss: 0.0975 - my_categorical_accuracy: 0.9759 - val_loss: 0.1254 - val_my_categorical_accuracy: 0.9496 - 5s/epoch - 10ms/step\n",
            "Epoch 33/150\n",
            "489/489 - 5s - loss: 0.0957 - my_categorical_accuracy: 0.9760 - val_loss: 0.1260 - val_my_categorical_accuracy: 0.9490 - 5s/epoch - 9ms/step\n",
            "Epoch 34/150\n",
            "489/489 - 5s - loss: 0.0937 - my_categorical_accuracy: 0.9765 - val_loss: 0.1517 - val_my_categorical_accuracy: 0.9338 - 5s/epoch - 9ms/step\n",
            "Epoch 35/150\n",
            "489/489 - 5s - loss: 0.0920 - my_categorical_accuracy: 0.9767 - val_loss: 0.1223 - val_my_categorical_accuracy: 0.9511 - 5s/epoch - 9ms/step\n",
            "Epoch 36/150\n",
            "489/489 - 5s - loss: 0.0901 - my_categorical_accuracy: 0.9771 - val_loss: 0.1404 - val_my_categorical_accuracy: 0.9392 - 5s/epoch - 9ms/step\n",
            "Epoch 37/150\n",
            "489/489 - 5s - loss: 0.0888 - my_categorical_accuracy: 0.9771 - val_loss: 0.1435 - val_my_categorical_accuracy: 0.9384 - 5s/epoch - 9ms/step\n",
            "Epoch 38/150\n",
            "489/489 - 5s - loss: 0.0873 - my_categorical_accuracy: 0.9774 - val_loss: 0.1291 - val_my_categorical_accuracy: 0.9477 - 5s/epoch - 9ms/step\n",
            "Epoch 39/150\n",
            "489/489 - 6s - loss: 0.0858 - my_categorical_accuracy: 0.9777 - val_loss: 0.1469 - val_my_categorical_accuracy: 0.9377 - 6s/epoch - 12ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd5c67e2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_SRQhd93Qf_W",
        "93Bz50lEQWpN",
        "d1sXdTaZQ5NI",
        "cMb0itb9UOQ2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}