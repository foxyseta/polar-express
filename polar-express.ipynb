{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Polar Express\n",
        "\n",
        "Stefano Volpe #0000969766\n",
        "\n",
        "University of Bologna\n",
        "\n",
        "Introduction to Machine Learning\n",
        "\n",
        "a.y. 2022/23"
      ],
      "metadata": {
        "id": "iLddMBwtQMuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "_SRQhd93Qf_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.activations import elu, gelu, relu, sigmoid, softmax, softsign, \\\n",
        "  swish, tanh\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Concatenate, Dense, Input, Normalization\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Nadam\n",
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "Ix4yJ9OVq4ka"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator"
      ],
      "metadata": {
        "id": "93Bz50lEQWpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def polar_generator(batchsize, grid = (10, 10), noise = .002, flat = False):\n",
        "  while True:\n",
        "    x = np.random.rand(batchsize)\n",
        "    y = np.random.rand(batchsize)\n",
        "    out = np.zeros((batchsize, grid[0], grid[1]))\n",
        "    xc = (x * grid[0]).astype(int)\n",
        "    yc = (y * grid[1]).astype(int)\n",
        "    for b in range(batchsize):\n",
        "      out[b,xc[b],yc[b]] = 1\n",
        "    # compute rho and theta and add some noise\n",
        "    rho = np.sqrt(x ** 2 + y ** 2) + np.random.normal(scale = noise)\n",
        "    theta = np.arctan(y / np.maximum(x, .00001)) + \\\n",
        "      np.random.normal(scale = noise)\n",
        "    if flat:\n",
        "      out = np.reshape(out, (batchsize, grid[0]*grid[1]))\n",
        "    yield ((theta,rho),out)"
      ],
      "metadata": {
        "id": "2NyUrOH2QKwJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "The project requirements ask for a size of the validation greater or equal than 20000. In order for it to be one fourth of the training set (which is a good rule of thumb in general), 1000000 was chosen. "
      ],
      "metadata": {
        "id": "d1sXdTaZQ5NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set_size, validation_set_size = 2000000, 500000\n",
        "\n",
        "(training_theta, training_rho), training_maps = next(polar_generator(training_set_size, flat = True))\n",
        "(validation_theta, validation_rho), validation_maps = next(polar_generator(training_set_size, flat = True))"
      ],
      "metadata": {
        "id": "C0_hDTg0Q94c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics\n",
        "\n",
        "The project requirements ask to compute the categorical accuracy of your model on your own, rather than using Keras's implementation."
      ],
      "metadata": {
        "id": "cMb0itb9UOQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def argmax_axis_1(input: tf.Tensor) -> int:\n",
        "  return tf.argmax(input, axis = 1)\n",
        "\n",
        "def my_categorical_accuracy(y_true : tf.Tensor, y_pred : tf.Tensor) -> tf.float64:\n",
        "  # The right categories (according to our ground truth)\n",
        "  y_true_argmax = argmax_axis_1(y_true)\n",
        "  # The predictions our model assert with the most confidence\n",
        "  y_pred_argmax = argmax_axis_1(y_pred)\n",
        "  # Element-wise equality\n",
        "  equalities = tf.equal(y_true_argmax, y_pred_argmax)\n",
        "  # Since True converts to 1.0, accuracy and arithmetic mean are\n",
        "  # equivalent\n",
        "  equalities = tf.cast(equalities, tf.float64)\n",
        "  return tf.reduce_mean(equalities)"
      ],
      "metadata": {
        "id": "cIA03P1QsN0k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "MaEiD0dGVsoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_set_size = 10000\n",
        "\n",
        "def makeNetwork() -> Model:\n",
        "  theta_input = Input(shape = (1, ))\n",
        "  theta_norm = Normalization(axis = None)\n",
        "  theta_norm.adapt(training_theta[:normalization_set_size])\n",
        "  theta_norm = theta_norm(theta_input)\n",
        "  theta_branch = Dense(2, activation = softsign)(theta_norm)\n",
        "  theta_branch = Dense(4, activation = tanh)(theta_branch)\n",
        "  theta_branch = Dense(4, activation = sigmoid)(theta_branch)\n",
        "\n",
        "  rho_input = Input(shape = (1,))\n",
        "  rho_norm = Normalization(axis = None)\n",
        "  rho_norm.adapt(training_rho[:normalization_set_size])\n",
        "  rho_norm = rho_norm(rho_input)\n",
        "  rho_branch = Dense(4, activation = softsign)(rho_norm)\n",
        "  rho_branch = Dense(4, activation = swish)(rho_branch)\n",
        "  rho_branch = Dense(4, activation = tanh)(rho_branch)\n",
        "  rho_branch = Dense(4, activation = elu)(rho_branch)\n",
        "\n",
        "  concatenate_layer = Concatenate()([theta_branch, rho_branch])\n",
        "  output = Dense(8, activation = swish)(concatenate_layer)\n",
        "  output = Dense(8, activation = relu)(output)\n",
        "  output = Dense(4, activation = gelu)(output)\n",
        "  output = Dense(100, activation = softmax)(output)\n",
        "  return Model([theta_input, rho_input], output)\n",
        "\n",
        "network = makeNetwork()\n",
        "network.build((None, 2))\n",
        "network.summary(show_trainable = False)\n",
        "plot_model(\n",
        "  network,\n",
        "  show_shapes = True,\n",
        "  show_dtype = True,\n",
        "  show_layer_activations = True,\n",
        ")\n",
        "network.compile(\n",
        "  Nadam(),\n",
        "  CategoricalCrossentropy(),\n",
        "  metrics = [my_categorical_accuracy]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiKzWgkAsevu",
        "outputId": "3cc8c32d-22a0-4c5b-f4f7-95a8c705a267"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " normalization_3 (Normalization  (None, 1)           3           ['input_4[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " normalization_2 (Normalization  (None, 1)           3           ['input_3[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 4)            8           ['normalization_3[0][0]']        \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 2)            4           ['normalization_2[0][0]']        \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 4)            20          ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 4)            12          ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 4)            20          ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 4)            20          ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 4)            20          ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 8)            0           ['dense_13[0][0]',               \n",
            "                                                                  'dense_17[0][0]']               \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 8)            72          ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 8)            72          ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 4)            36          ['dense_19[0][0]']               \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 100)          500         ['dense_20[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 790\n",
            "Trainable params: 784\n",
            "Non-trainable params: 6\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and evaluation"
      ],
      "metadata": {
        "id": "cWDtZr8fZw95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4096\n",
        "epochs = 150\n",
        "verbose = 2\n",
        "\n",
        "network.fit(\n",
        "  (training_theta, training_rho),\n",
        "  training_maps,\n",
        "  batch_size,\n",
        "  epochs,\n",
        "  verbose,\n",
        "  [EarlyStopping(monitor = 'val_loss', patience = 4)],\n",
        "  validation_data = ((validation_theta, validation_rho), validation_maps)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnRfV1eQtDNe",
        "outputId": "db241dab-af95-4662-d68f-45558930afec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "489/489 - 8s - loss: 3.7653 - my_categorical_accuracy: 0.0587 - val_loss: 2.6126 - val_my_categorical_accuracy: 0.1895 - 8s/epoch - 15ms/step\n",
            "Epoch 2/150\n",
            "489/489 - 6s - loss: 1.5871 - my_categorical_accuracy: 0.4870 - val_loss: 0.9747 - val_my_categorical_accuracy: 0.6680 - 6s/epoch - 12ms/step\n",
            "Epoch 3/150\n",
            "489/489 - 6s - loss: 0.7419 - my_categorical_accuracy: 0.7837 - val_loss: 0.6141 - val_my_categorical_accuracy: 0.8015 - 6s/epoch - 12ms/step\n",
            "Epoch 4/150\n",
            "489/489 - 6s - loss: 0.5096 - my_categorical_accuracy: 0.8592 - val_loss: 0.4649 - val_my_categorical_accuracy: 0.8577 - 6s/epoch - 12ms/step\n",
            "Epoch 5/150\n",
            "489/489 - 5s - loss: 0.4024 - my_categorical_accuracy: 0.8868 - val_loss: 0.3815 - val_my_categorical_accuracy: 0.8795 - 5s/epoch - 9ms/step\n",
            "Epoch 6/150\n",
            "489/489 - 6s - loss: 0.3388 - my_categorical_accuracy: 0.9045 - val_loss: 0.3377 - val_my_categorical_accuracy: 0.8905 - 6s/epoch - 12ms/step\n",
            "Epoch 7/150\n",
            "489/489 - 5s - loss: 0.2954 - my_categorical_accuracy: 0.9177 - val_loss: 0.3079 - val_my_categorical_accuracy: 0.8972 - 5s/epoch - 9ms/step\n",
            "Epoch 8/150\n",
            "489/489 - 6s - loss: 0.2633 - my_categorical_accuracy: 0.9281 - val_loss: 0.2618 - val_my_categorical_accuracy: 0.9194 - 6s/epoch - 12ms/step\n",
            "Epoch 9/150\n",
            "489/489 - 5s - loss: 0.2383 - my_categorical_accuracy: 0.9365 - val_loss: 0.2502 - val_my_categorical_accuracy: 0.9205 - 5s/epoch - 9ms/step\n",
            "Epoch 10/150\n",
            "489/489 - 5s - loss: 0.2165 - my_categorical_accuracy: 0.9441 - val_loss: 0.2239 - val_my_categorical_accuracy: 0.9296 - 5s/epoch - 9ms/step\n",
            "Epoch 11/150\n",
            "489/489 - 5s - loss: 0.1994 - my_categorical_accuracy: 0.9497 - val_loss: 0.2129 - val_my_categorical_accuracy: 0.9305 - 5s/epoch - 9ms/step\n",
            "Epoch 12/150\n",
            "489/489 - 6s - loss: 0.1856 - my_categorical_accuracy: 0.9542 - val_loss: 0.2085 - val_my_categorical_accuracy: 0.9266 - 6s/epoch - 12ms/step\n",
            "Epoch 13/150\n",
            "489/489 - 5s - loss: 0.1742 - my_categorical_accuracy: 0.9576 - val_loss: 0.1932 - val_my_categorical_accuracy: 0.9333 - 5s/epoch - 9ms/step\n",
            "Epoch 14/150\n",
            "489/489 - 5s - loss: 0.1644 - my_categorical_accuracy: 0.9602 - val_loss: 0.1870 - val_my_categorical_accuracy: 0.9341 - 5s/epoch - 9ms/step\n",
            "Epoch 15/150\n",
            "489/489 - 6s - loss: 0.1560 - my_categorical_accuracy: 0.9625 - val_loss: 0.2090 - val_my_categorical_accuracy: 0.9171 - 6s/epoch - 11ms/step\n",
            "Epoch 16/150\n",
            "489/489 - 6s - loss: 0.1484 - my_categorical_accuracy: 0.9648 - val_loss: 0.1677 - val_my_categorical_accuracy: 0.9434 - 6s/epoch - 12ms/step\n",
            "Epoch 17/150\n",
            "489/489 - 6s - loss: 0.1423 - my_categorical_accuracy: 0.9658 - val_loss: 0.1655 - val_my_categorical_accuracy: 0.9403 - 6s/epoch - 12ms/step\n",
            "Epoch 18/150\n",
            "489/489 - 5s - loss: 0.1362 - my_categorical_accuracy: 0.9675 - val_loss: 0.1632 - val_my_categorical_accuracy: 0.9398 - 5s/epoch - 9ms/step\n",
            "Epoch 19/150\n",
            "489/489 - 5s - loss: 0.1312 - my_categorical_accuracy: 0.9685 - val_loss: 0.1675 - val_my_categorical_accuracy: 0.9359 - 5s/epoch - 9ms/step\n",
            "Epoch 20/150\n",
            "489/489 - 6s - loss: 0.1264 - my_categorical_accuracy: 0.9698 - val_loss: 0.1637 - val_my_categorical_accuracy: 0.9363 - 6s/epoch - 11ms/step\n",
            "Epoch 21/150\n",
            "489/489 - 6s - loss: 0.1222 - my_categorical_accuracy: 0.9705 - val_loss: 0.1572 - val_my_categorical_accuracy: 0.9394 - 6s/epoch - 12ms/step\n",
            "Epoch 22/150\n",
            "489/489 - 5s - loss: 0.1183 - my_categorical_accuracy: 0.9712 - val_loss: 0.1414 - val_my_categorical_accuracy: 0.9501 - 5s/epoch - 9ms/step\n",
            "Epoch 23/150\n",
            "489/489 - 6s - loss: 0.1147 - my_categorical_accuracy: 0.9721 - val_loss: 0.1531 - val_my_categorical_accuracy: 0.9385 - 6s/epoch - 12ms/step\n",
            "Epoch 24/150\n",
            "489/489 - 6s - loss: 0.1114 - my_categorical_accuracy: 0.9727 - val_loss: 0.1342 - val_my_categorical_accuracy: 0.9505 - 6s/epoch - 12ms/step\n",
            "Epoch 25/150\n",
            "489/489 - 6s - loss: 0.1084 - my_categorical_accuracy: 0.9733 - val_loss: 0.1343 - val_my_categorical_accuracy: 0.9509 - 6s/epoch - 12ms/step\n",
            "Epoch 26/150\n",
            "489/489 - 5s - loss: 0.1058 - my_categorical_accuracy: 0.9736 - val_loss: 0.1498 - val_my_categorical_accuracy: 0.9390 - 5s/epoch - 9ms/step\n",
            "Epoch 27/150\n",
            "489/489 - 6s - loss: 0.1030 - my_categorical_accuracy: 0.9742 - val_loss: 0.1458 - val_my_categorical_accuracy: 0.9424 - 6s/epoch - 12ms/step\n",
            "Epoch 28/150\n",
            "489/489 - 6s - loss: 0.1006 - my_categorical_accuracy: 0.9746 - val_loss: 0.1371 - val_my_categorical_accuracy: 0.9442 - 6s/epoch - 12ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd5c13d340>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_SRQhd93Qf_W",
        "93Bz50lEQWpN",
        "d1sXdTaZQ5NI",
        "cMb0itb9UOQ2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}