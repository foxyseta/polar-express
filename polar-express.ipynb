{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Polar Express\n",
        "\n",
        "Stefano Volpe #0000969766\n",
        "\n",
        "University of Bologna\n",
        "\n",
        "Introduction to Machine Learning\n",
        "\n",
        "a.y. 2022/23"
      ],
      "metadata": {
        "id": "iLddMBwtQMuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "_SRQhd93Qf_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.activations import elu, gelu, relu, sigmoid, softmax, softsign, \\\n",
        "  swish, tanh\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Concatenate, Dense, Input, Normalization\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Nadam\n",
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "Ix4yJ9OVq4ka"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator"
      ],
      "metadata": {
        "id": "93Bz50lEQWpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def polar_generator(batchsize, grid = (10, 10), noise = .002, flat = False):\n",
        "  while True:\n",
        "    x = np.random.rand(batchsize)\n",
        "    y = np.random.rand(batchsize)\n",
        "    out = np.zeros((batchsize, grid[0], grid[1]))\n",
        "    xc = (x * grid[0]).astype(int)\n",
        "    yc = (y * grid[1]).astype(int)\n",
        "    for b in range(batchsize):\n",
        "      out[b,xc[b],yc[b]] = 1\n",
        "    # compute rho and theta and add some noise\n",
        "    rho = np.sqrt(x ** 2 + y ** 2) + np.random.normal(scale = noise)\n",
        "    theta = np.arctan(y / np.maximum(x, .00001)) + \\\n",
        "      np.random.normal(scale = noise)\n",
        "    if flat:\n",
        "      out = np.reshape(out, (batchsize, grid[0]*grid[1]))\n",
        "    yield ((theta,rho),out)"
      ],
      "metadata": {
        "id": "2NyUrOH2QKwJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "The project requirements ask for a size of the validation greater or equal than 20000. In order for it to be one fourth of the training set (which is a good rule of thumb in general), 1000000 was chosen. "
      ],
      "metadata": {
        "id": "d1sXdTaZQ5NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set_size, validation_set_size = 4000000, 1000000\n",
        "\n",
        "(training_theta, training_rho), training_maps = next(polar_generator(training_set_size, flat = True))\n",
        "(validation_theta, validation_rho), validation_maps = next(polar_generator(training_set_size, flat = True))"
      ],
      "metadata": {
        "id": "C0_hDTg0Q94c"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics\n",
        "\n",
        "The project requirements ask to compute the categorical accuracy of your model on your own, rather than using Keras's implementation."
      ],
      "metadata": {
        "id": "cMb0itb9UOQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def argmax_axis_1(input: tf.Tensor) -> int:\n",
        "  return tf.argmax(input, axis = 1)\n",
        "\n",
        "def my_categorical_accuracy(y_true : tf.Tensor, y_pred : tf.Tensor) -> tf.float64:\n",
        "  # The right categories (according to our ground truth)\n",
        "  y_true_argmax = argmax_axis_1(y_true)\n",
        "  # The predictions our model assert with the most confidence\n",
        "  y_pred_argmax = argmax_axis_1(y_pred)\n",
        "  # Element-wise equality\n",
        "  equalities = tf.equal(y_true_argmax, y_pred_argmax)\n",
        "  # Since True converts to 1.0, accuracy and arithmetic mean are\n",
        "  # equivalent\n",
        "  equalities = tf.cast(equalities, tf.float64)\n",
        "  return tf.reduce_mean(equalities)"
      ],
      "metadata": {
        "id": "cIA03P1QsN0k"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "MaEiD0dGVsoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeNetwork() -> Model:\n",
        "  theta_input = Input(shape = (1, ))\n",
        "  theta_norm = Normalization(axis = None)\n",
        "  theta_norm.adapt(training_theta)\n",
        "  theta_norm = theta_norm(theta_input)\n",
        "  theta_branch = Dense(2, activation = softsign)(theta_norm)\n",
        "  theta_branch = Dense(4, activation = tanh)(theta_branch)\n",
        "  theta_branch = Dense(4, activation = sigmoid)(theta_branch)\n",
        "\n",
        "  rho_input = Input(shape = (1,))\n",
        "  rho_norm = Normalization(axis = None)\n",
        "  rho_norm.adapt(training_rho)\n",
        "  rho_norm = rho_norm(rho_input)\n",
        "\n",
        "  rho_branch = Dense(4, activation = softsign)(rho_norm)\n",
        "  rho_branch = Dense(4, activation = swish)(rho_branch)\n",
        "  rho_branch = Dense(4, activation = tanh)(rho_branch)\n",
        "  rho_branch = Dense(4, activation = elu)(rho_branch)\n",
        "\n",
        "  concatenate_layer = Concatenate()([theta_branch, rho_branch])\n",
        "  output = Dense(8, activation = swish)(concatenate_layer)\n",
        "  output = Dense(16, activation = relu)(output)\n",
        "  output = Dense(4, activation = gelu)(output)\n",
        "  output = Dense(100, activation = softmax)(output)\n",
        "  return Model([theta_input, rho_input], output)\n",
        "\n",
        "network = makeNetwork()\n",
        "network.build((None, 2))\n",
        "network.summary(show_trainable = False)\n",
        "plot_model(\n",
        "  network,\n",
        "  show_shapes = True,\n",
        "  show_dtype = True,\n",
        "  show_layer_activations = True,\n",
        ")\n",
        "network.compile(\n",
        "  Nadam(),\n",
        "  CategoricalCrossentropy(),\n",
        "  metrics = [my_categorical_accuracy]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiKzWgkAsevu",
        "outputId": "8c21dff8-e46a-433b-d3f8-13edd6420fe1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " normalization_2 (Normalization  (None, 1)           3           ['input_3[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " normalization_1 (Normalization  (None, 1)           3           ['input_2[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 4)            8           ['normalization_2[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            4           ['normalization_1[0][0]']        \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 4)            20          ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 4)            12          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 4)            20          ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            20          ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 4)            20          ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8)            0           ['dense_2[0][0]',                \n",
            "                                                                  'dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 8)            72          ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 16)           144         ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 4)            68          ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 100)          500         ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 894\n",
            "Trainable params: 888\n",
            "Non-trainable params: 6\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and evaluation"
      ],
      "metadata": {
        "id": "cWDtZr8fZw95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4096\n",
        "epochs = 150\n",
        "verbose = 2\n",
        "\n",
        "network.fit(\n",
        "  (training_theta, training_rho),\n",
        "  training_maps,\n",
        "  batch_size,\n",
        "  epochs,\n",
        "  verbose,\n",
        "  [EarlyStopping(monitor = 'val_loss', patience = 4)],\n",
        "  validation_data = ((validation_theta, validation_rho), validation_maps)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnRfV1eQtDNe",
        "outputId": "f370bc3d-2e7e-466f-a950-fbb9c74e25cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Model.fit of <keras.engine.functional.Functional object at 0x7fa1f3d15730>>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_SRQhd93Qf_W",
        "93Bz50lEQWpN",
        "d1sXdTaZQ5NI",
        "cMb0itb9UOQ2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}