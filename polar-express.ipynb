{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import + codice del prof: non serve personalizzarmi\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import activations\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, Normalization\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def polar_generator(batchsize,grid=(10,10),noise=.002,flat=False):\n",
        "  while True:\n",
        "    x = np.random.rand(batchsize)\n",
        "    y = np.random.rand(batchsize)\n",
        "    out = np.zeros((batchsize,grid[0],grid[1]))\n",
        "    xc = (x*grid[0]).astype(int)\n",
        "    yc = (y*grid[1]).astype(int)\n",
        "    for b in range(batchsize):\n",
        "      out[b,xc[b],yc[b]] = 1\n",
        "    #compute rho and theta and add some noise\n",
        "    rho = np.sqrt(x**2+y**2) + np.random.normal(scale=noise)\n",
        "    theta = np.arctan(y/np.maximum(x,.00001)) + np.random.normal(scale=noise)\n",
        "    if flat:\n",
        "      out = np.reshape(out,(batchsize,grid[0]*grid[1]))\n",
        "    yield ((theta,rho),out)"
      ],
      "metadata": {
        "id": "Ix4yJ9OVq4ka"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iperparametri: personalizzami i valori e i nomi senza scasinare i risultati\n",
        "n_train = 4000000\n",
        "n_test = 20000\n",
        "batch_size = 4096"
      ],
      "metadata": {
        "id": "ro9TNMNIrEHG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Popolazioni: personalizzami i nomi e rifattorizza\n",
        "g1,g2 = 10,10\n",
        "gen = polar_generator(n_train+n_test,grid=(g1,g2),noise=0.002,flat=True)\n",
        "(theta,rho),y = next(gen)\n",
        "x=np.array([i for i in zip(theta,rho)])\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=n_test/(n_train+n_test), shuffle=True, random_state=1)"
      ],
      "metadata": {
        "id": "3JhHbUiSrmI9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuratezza: riscrivi in modo che calcoli la stessa cosa ma in modo diverso\n",
        "def discretized_accuracy(true_maps, my_maps):\n",
        "  equals = tf.equal(tf.argmax(true_maps, axis=1), tf.argmax(my_maps, axis=1))\n",
        "  return tf.cast(tf.math.count_nonzero(equals), tf.float64) / tf.cast(len(true_maps), tf.float64)"
      ],
      "metadata": {
        "id": "cIA03P1QsN0k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rete: cambia i nomi delle variabili e la grandezza delle reti dense senza scasinare i risultati\n",
        "theta_input = Input(shape=(1,))\n",
        "theta_norm = Normalization(axis=None)\n",
        "theta_norm.adapt(x_train[:,0])\n",
        "theta_norm = theta_norm(theta_input)\n",
        "theta_branch = Dense(2, activation=activations.softsign)(theta_norm)\n",
        "theta_branch = Dense(4, activation=activations.tanh)(theta_branch)\n",
        "theta_branch = Dense(4, activation=activations.sigmoid)(theta_branch)\n",
        "\n",
        "rho_input = Input(shape=(1,))\n",
        "rho_norm = Normalization(axis=None)\n",
        "rho_norm.adapt(x_train[:,1])\n",
        "rho_norm = rho_norm(rho_input)\n",
        "\n",
        "rho_branch = Dense(4, activation=activations.softsign)(rho_norm)\n",
        "rho_branch = Dense(4, activation=activations.swish)(rho_branch)\n",
        "rho_branch = Dense(4, activation=activations.tanh)(rho_branch)\n",
        "rho_branch = Dense(4, activation=activations.elu)(rho_branch)\n",
        "\n",
        "concatenate_layer = Concatenate()([theta_branch, rho_branch])\n",
        "output = layers.Dense(8, activation=keras.activations.swish)(concatenate_layer)\n",
        "output = layers.Dense(16, activation=keras.activations.relu)(output)\n",
        "output = layers.Dense(4, activation=keras.activations.gelu)(output)\n",
        "output = layers.Dense(100, activation=activations.softmax)(output)\n",
        "\n",
        "network = Model([theta_input, rho_input], output)\n",
        "network.build((None, 2))\n",
        "network.summary()\n",
        "network.compile(\n",
        "  optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=keras.losses.CategoricalCrossentropy(),\n",
        "  metrics=['accuracy', discretized_accuracy]\n",
        ")"
      ],
      "metadata": {
        "id": "IiKzWgkAsevu",
        "outputId": "4afb8f3f-f7b9-4e07-f351-79384db679f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " normalization_1 (Normalization  (None, 1)           3           ['input_2[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " normalization (Normalization)  (None, 1)            3           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 4)            8           ['normalization_1[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            4           ['normalization[0][0]']          \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 4)            20          ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 4)            12          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 4)            20          ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            20          ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 4)            20          ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8)            0           ['dense_2[0][0]',                \n",
            "                                                                  'dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 8)            72          ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 16)           144         ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 4)            68          ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 100)          500         ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 894\n",
            "Trainable params: 888\n",
            "Non-trainable params: 6\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prima della consegna, cancella tutto tranne:\n",
        "# - la chiamata a fit\n",
        "# - la prima chiamata a evaluate\n",
        "# - la prima print del \"Test Score\"\n",
        "# - la prima print dell'\"Accuracy\"\n",
        "# Personalizza tutte le print.\n",
        "load = input('wanna load previous weights?')\n",
        "if load == 'y':\n",
        "    network = keras.models.load_model(\"pesi\")\n",
        "\n",
        "while True:\n",
        "    history = network.fit(\n",
        "      x=[x_train[:,0], x_train[:,1]],\n",
        "      y=y_train,\n",
        "      epochs=15,\n",
        "      batch_size=batch_size,\n",
        "      validation_data=([x_test[:,0], x_test[:,1]], y_test),\n",
        "      callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)]\n",
        "    )\n",
        "    train = input('train again?')\n",
        "    if train != 'y':\n",
        "        break\n",
        "\n",
        "score, _, acc  = network.evaluate([x_test[:,0], x_test[:,1]], y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Accuracy: {:.1f}%'.format(acc*100))\n",
        "\n",
        "save = input('wanna load previous weights?')\n",
        "if save == 'y':\n",
        "    network.save(\"pesi\")\n",
        "\n",
        "while True:\n",
        "    gen = polar_generator(20000,grid=(g1,g2),noise=0.002,flat=True)\n",
        "    accs = 0.0\n",
        "    lower = 0\n",
        "    iters = 100\n",
        "    for x in range(iters):\n",
        "      (theta,rho),y = next(gen)\n",
        "      x=np.array([i for i in zip(theta,rho)])\n",
        "\n",
        "      score, _, acc = network.evaluate([x[:,0], x[:,1]], y, batch_size=batch_size)\n",
        "      accs += acc\n",
        "      if acc < 0.95:\n",
        "        lower += 1\n",
        "\n",
        "    print('------------------------')\n",
        "    print('Accuracy: {:.1f}%'.format(accs/iters*100))\n",
        "    print('Lower than 95%: {}/{}'.format(lower, iters))\n",
        "    print('------------------------')\n",
        "\n",
        "    test = input('test again?')\n",
        "    if test != 'y':\n",
        "        break"
      ],
      "metadata": {
        "id": "jnRfV1eQtDNe",
        "outputId": "c52afc08-b371-4e14-eacd-5d9d0eda3302",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wanna load previous weights?n\n",
            "Epoch 1/15\n",
            "977/977 [==============================] - 18s 18ms/step - loss: 0.1181 - accuracy: 0.9607 - discretized_accuracy: 0.9607 - val_loss: 0.1170 - val_accuracy: 0.9610 - val_discretized_accuracy: 0.9609\n",
            "Epoch 2/15\n",
            "977/977 [==============================] - 17s 18ms/step - loss: 0.1140 - accuracy: 0.9622 - discretized_accuracy: 0.9622 - val_loss: 0.1134 - val_accuracy: 0.9619 - val_discretized_accuracy: 0.9619\n",
            "Epoch 3/15\n",
            "977/977 [==============================] - 18s 18ms/step - loss: 0.1116 - accuracy: 0.9623 - discretized_accuracy: 0.9623 - val_loss: 0.1103 - val_accuracy: 0.9614 - val_discretized_accuracy: 0.9614\n",
            "Epoch 4/15\n",
            "977/977 [==============================] - 17s 18ms/step - loss: 0.1082 - accuracy: 0.9636 - discretized_accuracy: 0.9636 - val_loss: 0.1055 - val_accuracy: 0.9635 - val_discretized_accuracy: 0.9635\n",
            "Epoch 5/15\n",
            "977/977 [==============================] - 19s 19ms/step - loss: 0.1057 - accuracy: 0.9641 - discretized_accuracy: 0.9641 - val_loss: 0.1047 - val_accuracy: 0.9631 - val_discretized_accuracy: 0.9630\n",
            "Epoch 6/15\n",
            "977/977 [==============================] - 18s 18ms/step - loss: 0.1038 - accuracy: 0.9640 - discretized_accuracy: 0.9640 - val_loss: 0.1087 - val_accuracy: 0.9604 - val_discretized_accuracy: 0.9604\n",
            "Epoch 7/15\n",
            "977/977 [==============================] - 17s 18ms/step - loss: 0.1014 - accuracy: 0.9648 - discretized_accuracy: 0.9648 - val_loss: 0.1027 - val_accuracy: 0.9631 - val_discretized_accuracy: 0.9630\n",
            "Epoch 8/15\n",
            "977/977 [==============================] - 17s 18ms/step - loss: 0.1001 - accuracy: 0.9647 - discretized_accuracy: 0.9647 - val_loss: 0.0985 - val_accuracy: 0.9643 - val_discretized_accuracy: 0.9641\n",
            "Epoch 9/15\n",
            "977/977 [==============================] - 17s 17ms/step - loss: 0.0980 - accuracy: 0.9654 - discretized_accuracy: 0.9654 - val_loss: 0.0913 - val_accuracy: 0.9685 - val_discretized_accuracy: 0.9685\n",
            "Epoch 10/15\n",
            "977/977 [==============================] - 17s 18ms/step - loss: 0.0965 - accuracy: 0.9657 - discretized_accuracy: 0.9657 - val_loss: 0.0986 - val_accuracy: 0.9639 - val_discretized_accuracy: 0.9640\n",
            "Epoch 11/15\n",
            "977/977 [==============================] - 18s 18ms/step - loss: 0.0950 - accuracy: 0.9661 - discretized_accuracy: 0.9661 - val_loss: 0.0973 - val_accuracy: 0.9638 - val_discretized_accuracy: 0.9636\n",
            "Epoch 12/15\n",
            "977/977 [==============================] - 18s 18ms/step - loss: 0.0944 - accuracy: 0.9658 - discretized_accuracy: 0.9658 - val_loss: 0.0977 - val_accuracy: 0.9642 - val_discretized_accuracy: 0.9641\n",
            "train again?n\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0977 - accuracy: 0.9642 - discretized_accuracy: 0.9641\n",
            "Test score: 0.09774185717105865\n",
            "Accuracy: 96.4%\n",
            "wanna load previous weights?n\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1290 - accuracy: 0.9475 - discretized_accuracy: 0.9475\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1276 - accuracy: 0.9474 - discretized_accuracy: 0.9474\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1307 - accuracy: 0.9467 - discretized_accuracy: 0.9467\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1121 - accuracy: 0.9555 - discretized_accuracy: 0.9555\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1010 - accuracy: 0.9628 - discretized_accuracy: 0.9628\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0990 - accuracy: 0.9641 - discretized_accuracy: 0.9642\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1362 - accuracy: 0.9444 - discretized_accuracy: 0.9444\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1087 - accuracy: 0.9561 - discretized_accuracy: 0.9561\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1062 - accuracy: 0.9586 - discretized_accuracy: 0.9585\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1100 - accuracy: 0.9581 - discretized_accuracy: 0.9580\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1610 - accuracy: 0.9333 - discretized_accuracy: 0.9333\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1211 - accuracy: 0.9503 - discretized_accuracy: 0.9503\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1253 - accuracy: 0.9482 - discretized_accuracy: 0.9483\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1206 - accuracy: 0.9503 - discretized_accuracy: 0.9502\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1226 - accuracy: 0.9488 - discretized_accuracy: 0.9487\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1081 - accuracy: 0.9567 - discretized_accuracy: 0.9565\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1460 - accuracy: 0.9338 - discretized_accuracy: 0.9338\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1260 - accuracy: 0.9504 - discretized_accuracy: 0.9504\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0992 - accuracy: 0.9632 - discretized_accuracy: 0.9632\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1165 - accuracy: 0.9523 - discretized_accuracy: 0.9522\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1139 - accuracy: 0.9531 - discretized_accuracy: 0.9533\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1189 - accuracy: 0.9516 - discretized_accuracy: 0.9515\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1360 - accuracy: 0.9431 - discretized_accuracy: 0.9430\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1508 - accuracy: 0.9323 - discretized_accuracy: 0.9322\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1143 - accuracy: 0.9525 - discretized_accuracy: 0.9526\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1343 - accuracy: 0.9459 - discretized_accuracy: 0.9460\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1181 - accuracy: 0.9488 - discretized_accuracy: 0.9487\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1612 - accuracy: 0.9359 - discretized_accuracy: 0.9360\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1184 - accuracy: 0.9517 - discretized_accuracy: 0.9517\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1112 - accuracy: 0.9544 - discretized_accuracy: 0.9544\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1368 - accuracy: 0.9409 - discretized_accuracy: 0.9409\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0965 - accuracy: 0.9639 - discretized_accuracy: 0.9638\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1074 - accuracy: 0.9572 - discretized_accuracy: 0.9573\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0964 - accuracy: 0.9638 - discretized_accuracy: 0.9637\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1770 - accuracy: 0.9269 - discretized_accuracy: 0.9269\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1420 - accuracy: 0.9416 - discretized_accuracy: 0.9415\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1015 - accuracy: 0.9612 - discretized_accuracy: 0.9612\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1029 - accuracy: 0.9607 - discretized_accuracy: 0.9608\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1179 - accuracy: 0.9517 - discretized_accuracy: 0.9515\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1249 - accuracy: 0.9487 - discretized_accuracy: 0.9487\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1717 - accuracy: 0.9267 - discretized_accuracy: 0.9268\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1352 - accuracy: 0.9416 - discretized_accuracy: 0.9417\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1054 - accuracy: 0.9600 - discretized_accuracy: 0.9601\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1473 - accuracy: 0.9348 - discretized_accuracy: 0.9347\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1593 - accuracy: 0.9356 - discretized_accuracy: 0.9358\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1269 - accuracy: 0.9463 - discretized_accuracy: 0.9462\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1914 - accuracy: 0.9257 - discretized_accuracy: 0.9257\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1045 - accuracy: 0.9590 - discretized_accuracy: 0.9588\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1111 - accuracy: 0.9572 - discretized_accuracy: 0.9573\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1142 - accuracy: 0.9559 - discretized_accuracy: 0.9559\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1048 - accuracy: 0.9588 - discretized_accuracy: 0.9588\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1282 - accuracy: 0.9481 - discretized_accuracy: 0.9482\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1136 - accuracy: 0.9546 - discretized_accuracy: 0.9547\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1269 - accuracy: 0.9464 - discretized_accuracy: 0.9463\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1125 - accuracy: 0.9543 - discretized_accuracy: 0.9542\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1159 - accuracy: 0.9553 - discretized_accuracy: 0.9553\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1333 - accuracy: 0.9434 - discretized_accuracy: 0.9433\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1362 - accuracy: 0.9440 - discretized_accuracy: 0.9440\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1126 - accuracy: 0.9554 - discretized_accuracy: 0.9554\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1068 - accuracy: 0.9574 - discretized_accuracy: 0.9574\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1184 - accuracy: 0.9501 - discretized_accuracy: 0.9499\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1028 - accuracy: 0.9608 - discretized_accuracy: 0.9609\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1125 - accuracy: 0.9562 - discretized_accuracy: 0.9562\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1283 - accuracy: 0.9438 - discretized_accuracy: 0.9439\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1050 - accuracy: 0.9590 - discretized_accuracy: 0.9590\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1050 - accuracy: 0.9576 - discretized_accuracy: 0.9577\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0999 - accuracy: 0.9629 - discretized_accuracy: 0.9628\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1012 - accuracy: 0.9622 - discretized_accuracy: 0.9622\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1002 - accuracy: 0.9627 - discretized_accuracy: 0.9628\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1085 - accuracy: 0.9565 - discretized_accuracy: 0.9565\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1031 - accuracy: 0.9590 - discretized_accuracy: 0.9591\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1078 - accuracy: 0.9564 - discretized_accuracy: 0.9565\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1065 - accuracy: 0.9586 - discretized_accuracy: 0.9587\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1158 - accuracy: 0.9553 - discretized_accuracy: 0.9552\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1163 - accuracy: 0.9526 - discretized_accuracy: 0.9527\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1112 - accuracy: 0.9568 - discretized_accuracy: 0.9568\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1247 - accuracy: 0.9469 - discretized_accuracy: 0.9469\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1465 - accuracy: 0.9344 - discretized_accuracy: 0.9343\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1045 - accuracy: 0.9589 - discretized_accuracy: 0.9590\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1207 - accuracy: 0.9520 - discretized_accuracy: 0.9519\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1013 - accuracy: 0.9606 - discretized_accuracy: 0.9605\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1967 - accuracy: 0.9233 - discretized_accuracy: 0.9233\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1523 - accuracy: 0.9370 - discretized_accuracy: 0.9370\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1107 - accuracy: 0.9552 - discretized_accuracy: 0.9552\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1337 - accuracy: 0.9464 - discretized_accuracy: 0.9464\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1576 - accuracy: 0.9355 - discretized_accuracy: 0.9356\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1056 - accuracy: 0.9592 - discretized_accuracy: 0.9591\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1315 - accuracy: 0.9453 - discretized_accuracy: 0.9454\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1213 - accuracy: 0.9499 - discretized_accuracy: 0.9499\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1197 - accuracy: 0.9501 - discretized_accuracy: 0.9502\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0985 - accuracy: 0.9650 - discretized_accuracy: 0.9651\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1065 - accuracy: 0.9583 - discretized_accuracy: 0.9583\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1298 - accuracy: 0.9464 - discretized_accuracy: 0.9464\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1050 - accuracy: 0.9611 - discretized_accuracy: 0.9611\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1034 - accuracy: 0.9603 - discretized_accuracy: 0.9603\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1280 - accuracy: 0.9477 - discretized_accuracy: 0.9477\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1180 - accuracy: 0.9516 - discretized_accuracy: 0.9515\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1132 - accuracy: 0.9537 - discretized_accuracy: 0.9538\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0963 - accuracy: 0.9635 - discretized_accuracy: 0.9635\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0974 - accuracy: 0.9635 - discretized_accuracy: 0.9635\n",
            "------------------------\n",
            "Accuracy: 95.1%\n",
            "Lower than 95%: 39/100\n",
            "------------------------\n",
            "test again?n\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
