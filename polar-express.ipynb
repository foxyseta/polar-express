{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Polar Express\n",
        "\n",
        "Stefano Volpe #0000969766\n",
        "\n",
        "University of Bologna\n",
        "\n",
        "Introduction to Machine Learning\n",
        "\n",
        "a.y. 2022/23"
      ],
      "metadata": {
        "id": "iLddMBwtQMuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "_SRQhd93Qf_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.activations import elu, gelu, relu, sigmoid, softmax, softsign, \\\n",
        "  swish, tanh\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Concatenate, Dense, Dropout, Input, Normalization\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Nadam\n",
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "Ix4yJ9OVq4ka"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator"
      ],
      "metadata": {
        "id": "93Bz50lEQWpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def polar_generator(batchsize, grid = (10, 10), noise = .002, flat = False):\n",
        "  while True:\n",
        "    x = np.random.rand(batchsize)\n",
        "    y = np.random.rand(batchsize)\n",
        "    out = np.zeros((batchsize, grid[0], grid[1]))\n",
        "    xc = (x * grid[0]).astype(int)\n",
        "    yc = (y * grid[1]).astype(int)\n",
        "    for b in range(batchsize):\n",
        "      out[b,xc[b],yc[b]] = 1\n",
        "    # compute rho and theta and add some noise\n",
        "    rho = np.sqrt(x ** 2 + y ** 2) + np.random.normal(scale = noise)\n",
        "    theta = np.arctan(y / np.maximum(x, .00001)) + \\\n",
        "      np.random.normal(scale = noise)\n",
        "    if flat:\n",
        "      out = np.reshape(out, (batchsize, grid[0]*grid[1]))\n",
        "    yield ((theta,rho),out)"
      ],
      "metadata": {
        "id": "2NyUrOH2QKwJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "The project requirements ask for a size of the validation greater or equal than 20000. In order for it to be one fourth of the training set (which is a good rule of thumb in general), 500000 was chosen. "
      ],
      "metadata": {
        "id": "d1sXdTaZQ5NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set_size, validation_set_size = 3000000, 750000\n",
        "\n",
        "(training_theta, training_rho), training_maps = next(polar_generator(training_set_size, flat = True))\n",
        "(validation_theta, validation_rho), validation_maps = next(polar_generator(training_set_size, flat = True))"
      ],
      "metadata": {
        "id": "C0_hDTg0Q94c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics\n",
        "\n",
        "The project requirements ask to compute the categorical accuracy of your model on your own, rather than using Keras's implementation."
      ],
      "metadata": {
        "id": "cMb0itb9UOQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def argmax_axis_1(input: tf.Tensor) -> int:\n",
        "  return tf.argmax(input, axis = 1)\n",
        "\n",
        "def my_categorical_accuracy(y_true : tf.Tensor, y_pred : tf.Tensor) -> tf.float64:\n",
        "  # The right categories (according to our ground truth)\n",
        "  y_true_argmax = argmax_axis_1(y_true)\n",
        "  # The predictions our model assert with the most confidence\n",
        "  y_pred_argmax = argmax_axis_1(y_pred)\n",
        "  # Element-wise equality\n",
        "  equalities = tf.equal(y_true_argmax, y_pred_argmax)\n",
        "  # Since True converts to 1.0, accuracy and arithmetic mean are\n",
        "  # equivalent\n",
        "  equalities = tf.cast(equalities, tf.float64)\n",
        "  return tf.reduce_mean(equalities)"
      ],
      "metadata": {
        "id": "cIA03P1QsN0k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "MaEiD0dGVsoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_set_size = 10000\n",
        "\n",
        "def makeNetwork() -> Model:\n",
        "  theta = Input(shape = (1, ), name = \"Theta\")\n",
        "  theta_normalization = Normalization(axis = None, name = \"ThetaNormalization\")\n",
        "  theta_normalization.adapt(training_theta[:normalization_set_size])\n",
        "  theta_normalization = theta_normalization(theta)\n",
        "  a1 = Dense(2, activation = softsign, name = \"A1\")(theta_normalization)\n",
        "  a2 = Dense(4, activation = tanh, name = \"A2\")(a1)\n",
        "  a3 = Dense(4, activation = sigmoid, name = \"A3\")(a2)\n",
        "\n",
        "  rho = Input(shape = (1,), name = \"Rho\")\n",
        "  rho_normalization = Normalization(axis = None, name = \"RhoNormalization\")\n",
        "  rho_normalization.adapt(training_rho[:normalization_set_size])\n",
        "  rho_normalization = rho_normalization(rho)\n",
        "  b1 = Dense(4, activation = softsign, name = \"B1\")(rho_normalization)\n",
        "\n",
        "  ab1 = Concatenate(name = \"AB1\")([a3, b1])\n",
        "  ab2 = Dense(8, activation = swish, name = \"AB2\")(ab1)\n",
        "  ab3 = Dense(8, activation = relu, name = \"AB3\")(ab2)\n",
        "  ab4 = Dense(3, activation = gelu, name = \"AB4\")(ab3)\n",
        "  out = Dense(100, activation = softmax, name = \"out\")(ab4)\n",
        "  return Model([theta, rho], out)\n",
        "\n",
        "polar_express = makeNetwork()\n",
        "polar_express.build((None, 2))\n",
        "polar_express.summary(show_trainable = False)\n",
        "plot_model(\n",
        "  polar_express,\n",
        "  show_shapes = True,\n",
        "  show_dtype = True,\n",
        "  show_layer_activations = True,\n",
        ")\n",
        "polar_express.compile(\n",
        "  Nadam(),\n",
        "  CategoricalCrossentropy(),\n",
        "  metrics = [my_categorical_accuracy]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiKzWgkAsevu",
        "outputId": "089ac95e-b991-42ee-de91-c7628be5a691"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Theta (InputLayer)             [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " ThetaNormalization (Normalizat  (None, 1)           3           ['Theta[0][0]']                  \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " A1 (Dense)                     (None, 2)            4           ['ThetaNormalization[0][0]']     \n",
            "                                                                                                  \n",
            " Rho (InputLayer)               [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " A2 (Dense)                     (None, 4)            12          ['A1[0][0]']                     \n",
            "                                                                                                  \n",
            " RhoNormalization (Normalizatio  (None, 1)           3           ['Rho[0][0]']                    \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " A3 (Dense)                     (None, 4)            20          ['A2[0][0]']                     \n",
            "                                                                                                  \n",
            " B1 (Dense)                     (None, 4)            8           ['RhoNormalization[0][0]']       \n",
            "                                                                                                  \n",
            " AB1 (Concatenate)              (None, 8)            0           ['A3[0][0]',                     \n",
            "                                                                  'B1[0][0]']                     \n",
            "                                                                                                  \n",
            " AB2 (Dense)                    (None, 8)            72          ['AB1[0][0]']                    \n",
            "                                                                                                  \n",
            " AB3 (Dense)                    (None, 8)            72          ['AB2[0][0]']                    \n",
            "                                                                                                  \n",
            " AB4 (Dense)                    (None, 3)            27          ['AB3[0][0]']                    \n",
            "                                                                                                  \n",
            " out (Dense)                    (None, 100)          400         ['AB4[0][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 621\n",
            "Trainable params: 615\n",
            "Non-trainable params: 6\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and evaluation\n",
        "\n",
        "Here is the training history. For each epoch, the network has been evaluated via\n",
        "categorical accuracy on the validation set (see `val_my_categorical_accuracy`)."
      ],
      "metadata": {
        "id": "cWDtZr8fZw95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4096\n",
        "epochs = 99\n",
        "verbose = 2\n",
        "\n",
        "polar_express.fit(\n",
        "  (training_theta, training_rho),\n",
        "  training_maps,\n",
        "  batch_size,\n",
        "  epochs,\n",
        "  verbose,\n",
        "  [EarlyStopping(monitor = 'val_loss', patience = 4)],\n",
        "  validation_data = ((validation_theta, validation_rho), validation_maps)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnRfV1eQtDNe",
        "outputId": "663c7c8a-2a83-4aff-c37b-233099631e2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/99\n",
            "733/733 - 11s - loss: 3.4164 - my_categorical_accuracy: 0.1234 - val_loss: 2.3885 - val_my_categorical_accuracy: 0.2640 - 11s/epoch - 15ms/step\n",
            "Epoch 2/99\n",
            "733/733 - 7s - loss: 1.7421 - my_categorical_accuracy: 0.4805 - val_loss: 1.2630 - val_my_categorical_accuracy: 0.6370 - 7s/epoch - 9ms/step\n",
            "Epoch 3/99\n",
            "733/733 - 7s - loss: 0.9901 - my_categorical_accuracy: 0.7199 - val_loss: 0.7750 - val_my_categorical_accuracy: 0.7666 - 7s/epoch - 9ms/step\n",
            "Epoch 4/99\n",
            "733/733 - 9s - loss: 0.6743 - my_categorical_accuracy: 0.7987 - val_loss: 0.6091 - val_my_categorical_accuracy: 0.8114 - 9s/epoch - 13ms/step\n",
            "Epoch 5/99\n",
            "733/733 - 7s - loss: 0.5520 - my_categorical_accuracy: 0.8322 - val_loss: 0.5130 - val_my_categorical_accuracy: 0.8415 - 7s/epoch - 10ms/step\n",
            "Epoch 6/99\n",
            "733/733 - 6s - loss: 0.4723 - my_categorical_accuracy: 0.8549 - val_loss: 0.4503 - val_my_categorical_accuracy: 0.8569 - 6s/epoch - 9ms/step\n",
            "Epoch 7/99\n",
            "733/733 - 7s - loss: 0.4182 - my_categorical_accuracy: 0.8704 - val_loss: 0.4027 - val_my_categorical_accuracy: 0.8712 - 7s/epoch - 9ms/step\n",
            "Epoch 8/99\n",
            "733/733 - 7s - loss: 0.3776 - my_categorical_accuracy: 0.8838 - val_loss: 0.3657 - val_my_categorical_accuracy: 0.8869 - 7s/epoch - 9ms/step\n",
            "Epoch 9/99\n",
            "733/733 - 6s - loss: 0.3452 - my_categorical_accuracy: 0.8949 - val_loss: 0.3334 - val_my_categorical_accuracy: 0.8978 - 6s/epoch - 9ms/step\n",
            "Epoch 10/99\n",
            "733/733 - 7s - loss: 0.3164 - my_categorical_accuracy: 0.9061 - val_loss: 0.3093 - val_my_categorical_accuracy: 0.9044 - 7s/epoch - 9ms/step\n",
            "Epoch 11/99\n",
            "733/733 - 6s - loss: 0.2900 - my_categorical_accuracy: 0.9164 - val_loss: 0.2811 - val_my_categorical_accuracy: 0.9144 - 6s/epoch - 9ms/step\n",
            "Epoch 12/99\n",
            "733/733 - 9s - loss: 0.2588 - my_categorical_accuracy: 0.9289 - val_loss: 0.2484 - val_my_categorical_accuracy: 0.9308 - 9s/epoch - 13ms/step\n",
            "Epoch 13/99\n",
            "733/733 - 6s - loss: 0.2352 - my_categorical_accuracy: 0.9380 - val_loss: 0.2295 - val_my_categorical_accuracy: 0.9363 - 6s/epoch - 9ms/step\n",
            "Epoch 14/99\n",
            "733/733 - 7s - loss: 0.2180 - my_categorical_accuracy: 0.9438 - val_loss: 0.2161 - val_my_categorical_accuracy: 0.9397 - 7s/epoch - 9ms/step\n",
            "Epoch 15/99\n",
            "733/733 - 6s - loss: 0.2051 - my_categorical_accuracy: 0.9474 - val_loss: 0.2036 - val_my_categorical_accuracy: 0.9442 - 6s/epoch - 9ms/step\n",
            "Epoch 16/99\n",
            "733/733 - 6s - loss: 0.1938 - my_categorical_accuracy: 0.9504 - val_loss: 0.1957 - val_my_categorical_accuracy: 0.9454 - 6s/epoch - 9ms/step\n",
            "Epoch 17/99\n",
            "733/733 - 6s - loss: 0.1835 - my_categorical_accuracy: 0.9526 - val_loss: 0.1832 - val_my_categorical_accuracy: 0.9486 - 6s/epoch - 9ms/step\n",
            "Epoch 18/99\n",
            "733/733 - 6s - loss: 0.1739 - my_categorical_accuracy: 0.9546 - val_loss: 0.1751 - val_my_categorical_accuracy: 0.9470 - 6s/epoch - 9ms/step\n",
            "Epoch 19/99\n",
            "733/733 - 7s - loss: 0.1644 - my_categorical_accuracy: 0.9570 - val_loss: 0.1663 - val_my_categorical_accuracy: 0.9503 - 7s/epoch - 9ms/step\n",
            "Epoch 20/99\n",
            "733/733 - 6s - loss: 0.1550 - my_categorical_accuracy: 0.9594 - val_loss: 0.1543 - val_my_categorical_accuracy: 0.9579 - 6s/epoch - 9ms/step\n",
            "Epoch 21/99\n",
            "733/733 - 7s - loss: 0.1479 - my_categorical_accuracy: 0.9610 - val_loss: 0.1483 - val_my_categorical_accuracy: 0.9564 - 7s/epoch - 9ms/step\n",
            "Epoch 22/99\n",
            "733/733 - 6s - loss: 0.1414 - my_categorical_accuracy: 0.9623 - val_loss: 0.1440 - val_my_categorical_accuracy: 0.9560 - 6s/epoch - 9ms/step\n",
            "Epoch 23/99\n",
            "733/733 - 7s - loss: 0.1352 - my_categorical_accuracy: 0.9640 - val_loss: 0.1364 - val_my_categorical_accuracy: 0.9601 - 7s/epoch - 10ms/step\n",
            "Epoch 24/99\n",
            "733/733 - 6s - loss: 0.1303 - my_categorical_accuracy: 0.9654 - val_loss: 0.1303 - val_my_categorical_accuracy: 0.9638 - 6s/epoch - 9ms/step\n",
            "Epoch 25/99\n",
            "733/733 - 7s - loss: 0.1261 - my_categorical_accuracy: 0.9666 - val_loss: 0.1283 - val_my_categorical_accuracy: 0.9618 - 7s/epoch - 9ms/step\n",
            "Epoch 26/99\n",
            "733/733 - 6s - loss: 0.1223 - my_categorical_accuracy: 0.9675 - val_loss: 0.1228 - val_my_categorical_accuracy: 0.9650 - 6s/epoch - 9ms/step\n",
            "Epoch 27/99\n",
            "733/733 - 6s - loss: 0.1190 - my_categorical_accuracy: 0.9682 - val_loss: 0.1210 - val_my_categorical_accuracy: 0.9637 - 6s/epoch - 9ms/step\n",
            "Epoch 28/99\n",
            "733/733 - 7s - loss: 0.1160 - my_categorical_accuracy: 0.9689 - val_loss: 0.1173 - val_my_categorical_accuracy: 0.9667 - 7s/epoch - 9ms/step\n",
            "Epoch 29/99\n",
            "733/733 - 7s - loss: 0.1130 - my_categorical_accuracy: 0.9698 - val_loss: 0.1151 - val_my_categorical_accuracy: 0.9665 - 7s/epoch - 9ms/step\n",
            "Epoch 30/99\n",
            "733/733 - 6s - loss: 0.1104 - my_categorical_accuracy: 0.9703 - val_loss: 0.1142 - val_my_categorical_accuracy: 0.9643 - 6s/epoch - 9ms/step\n",
            "Epoch 31/99\n",
            "733/733 - 7s - loss: 0.1079 - my_categorical_accuracy: 0.9708 - val_loss: 0.1113 - val_my_categorical_accuracy: 0.9657 - 7s/epoch - 9ms/step\n",
            "Epoch 32/99\n",
            "733/733 - 7s - loss: 0.1057 - my_categorical_accuracy: 0.9712 - val_loss: 0.1080 - val_my_categorical_accuracy: 0.9679 - 7s/epoch - 10ms/step\n",
            "Epoch 33/99\n",
            "733/733 - 7s - loss: 0.1036 - my_categorical_accuracy: 0.9719 - val_loss: 0.1058 - val_my_categorical_accuracy: 0.9680 - 7s/epoch - 9ms/step\n",
            "Epoch 34/99\n",
            "733/733 - 7s - loss: 0.1016 - my_categorical_accuracy: 0.9722 - val_loss: 0.1075 - val_my_categorical_accuracy: 0.9637 - 7s/epoch - 9ms/step\n",
            "Epoch 35/99\n",
            "733/733 - 6s - loss: 0.0998 - my_categorical_accuracy: 0.9725 - val_loss: 0.1046 - val_my_categorical_accuracy: 0.9661 - 6s/epoch - 9ms/step\n",
            "Epoch 36/99\n",
            "733/733 - 6s - loss: 0.0981 - my_categorical_accuracy: 0.9729 - val_loss: 0.1004 - val_my_categorical_accuracy: 0.9699 - 6s/epoch - 9ms/step\n",
            "Epoch 37/99\n",
            "733/733 - 6s - loss: 0.0963 - my_categorical_accuracy: 0.9734 - val_loss: 0.0987 - val_my_categorical_accuracy: 0.9701 - 6s/epoch - 9ms/step\n",
            "Epoch 38/99\n",
            "733/733 - 7s - loss: 0.0948 - my_categorical_accuracy: 0.9737 - val_loss: 0.0953 - val_my_categorical_accuracy: 0.9723 - 7s/epoch - 9ms/step\n",
            "Epoch 39/99\n",
            "733/733 - 7s - loss: 0.0934 - my_categorical_accuracy: 0.9740 - val_loss: 0.0953 - val_my_categorical_accuracy: 0.9711 - 7s/epoch - 9ms/step\n",
            "Epoch 40/99\n",
            "733/733 - 6s - loss: 0.0919 - my_categorical_accuracy: 0.9744 - val_loss: 0.0953 - val_my_categorical_accuracy: 0.9698 - 6s/epoch - 9ms/step\n",
            "Epoch 41/99\n",
            "733/733 - 7s - loss: 0.0906 - my_categorical_accuracy: 0.9747 - val_loss: 0.0921 - val_my_categorical_accuracy: 0.9724 - 7s/epoch - 9ms/step\n",
            "Epoch 42/99\n",
            "733/733 - 7s - loss: 0.0892 - my_categorical_accuracy: 0.9750 - val_loss: 0.0916 - val_my_categorical_accuracy: 0.9722 - 7s/epoch - 10ms/step\n",
            "Epoch 43/99\n",
            "733/733 - 7s - loss: 0.0880 - my_categorical_accuracy: 0.9752 - val_loss: 0.0910 - val_my_categorical_accuracy: 0.9718 - 7s/epoch - 9ms/step\n",
            "Epoch 44/99\n",
            "733/733 - 7s - loss: 0.0870 - my_categorical_accuracy: 0.9754 - val_loss: 0.0908 - val_my_categorical_accuracy: 0.9711 - 7s/epoch - 9ms/step\n",
            "Epoch 45/99\n",
            "733/733 - 7s - loss: 0.0857 - my_categorical_accuracy: 0.9758 - val_loss: 0.0894 - val_my_categorical_accuracy: 0.9717 - 7s/epoch - 9ms/step\n",
            "Epoch 46/99\n",
            "733/733 - 7s - loss: 0.0848 - my_categorical_accuracy: 0.9760 - val_loss: 0.0893 - val_my_categorical_accuracy: 0.9712 - 7s/epoch - 9ms/step\n",
            "Epoch 47/99\n",
            "733/733 - 6s - loss: 0.0837 - my_categorical_accuracy: 0.9762 - val_loss: 0.0865 - val_my_categorical_accuracy: 0.9725 - 6s/epoch - 9ms/step\n",
            "Epoch 48/99\n",
            "733/733 - 7s - loss: 0.0827 - my_categorical_accuracy: 0.9765 - val_loss: 0.0832 - val_my_categorical_accuracy: 0.9760 - 7s/epoch - 9ms/step\n",
            "Epoch 49/99\n",
            "733/733 - 6s - loss: 0.0820 - my_categorical_accuracy: 0.9765 - val_loss: 0.0874 - val_my_categorical_accuracy: 0.9704 - 6s/epoch - 9ms/step\n",
            "Epoch 50/99\n",
            "733/733 - 7s - loss: 0.0810 - my_categorical_accuracy: 0.9768 - val_loss: 0.0821 - val_my_categorical_accuracy: 0.9751 - 7s/epoch - 9ms/step\n",
            "Epoch 51/99\n",
            "733/733 - 7s - loss: 0.0801 - my_categorical_accuracy: 0.9771 - val_loss: 0.0862 - val_my_categorical_accuracy: 0.9712 - 7s/epoch - 10ms/step\n",
            "Epoch 52/99\n",
            "733/733 - 6s - loss: 0.0794 - my_categorical_accuracy: 0.9771 - val_loss: 0.0836 - val_my_categorical_accuracy: 0.9730 - 6s/epoch - 9ms/step\n",
            "Epoch 53/99\n",
            "733/733 - 7s - loss: 0.0786 - my_categorical_accuracy: 0.9772 - val_loss: 0.0820 - val_my_categorical_accuracy: 0.9732 - 7s/epoch - 9ms/step\n",
            "Epoch 54/99\n",
            "733/733 - 7s - loss: 0.0777 - my_categorical_accuracy: 0.9773 - val_loss: 0.0828 - val_my_categorical_accuracy: 0.9712 - 7s/epoch - 9ms/step\n",
            "Epoch 55/99\n",
            "733/733 - 6s - loss: 0.0768 - my_categorical_accuracy: 0.9778 - val_loss: 0.0802 - val_my_categorical_accuracy: 0.9745 - 6s/epoch - 9ms/step\n",
            "Epoch 56/99\n",
            "733/733 - 6s - loss: 0.0761 - my_categorical_accuracy: 0.9777 - val_loss: 0.0801 - val_my_categorical_accuracy: 0.9734 - 6s/epoch - 9ms/step\n",
            "Epoch 57/99\n",
            "733/733 - 6s - loss: 0.0753 - my_categorical_accuracy: 0.9780 - val_loss: 0.0781 - val_my_categorical_accuracy: 0.9755 - 6s/epoch - 9ms/step\n",
            "Epoch 58/99\n",
            "733/733 - 7s - loss: 0.0747 - my_categorical_accuracy: 0.9780 - val_loss: 0.0776 - val_my_categorical_accuracy: 0.9745 - 7s/epoch - 9ms/step\n",
            "Epoch 59/99\n",
            "733/733 - 6s - loss: 0.0740 - my_categorical_accuracy: 0.9782 - val_loss: 0.0787 - val_my_categorical_accuracy: 0.9731 - 6s/epoch - 9ms/step\n",
            "Epoch 60/99\n",
            "733/733 - 6s - loss: 0.0734 - my_categorical_accuracy: 0.9783 - val_loss: 0.0756 - val_my_categorical_accuracy: 0.9757 - 6s/epoch - 9ms/step\n",
            "Epoch 61/99\n",
            "733/733 - 7s - loss: 0.0728 - my_categorical_accuracy: 0.9784 - val_loss: 0.0760 - val_my_categorical_accuracy: 0.9751 - 7s/epoch - 9ms/step\n",
            "Epoch 62/99\n",
            "733/733 - 7s - loss: 0.0722 - my_categorical_accuracy: 0.9786 - val_loss: 0.0767 - val_my_categorical_accuracy: 0.9736 - 7s/epoch - 10ms/step\n",
            "Epoch 63/99\n",
            "733/733 - 6s - loss: 0.0716 - my_categorical_accuracy: 0.9786 - val_loss: 0.0776 - val_my_categorical_accuracy: 0.9731 - 6s/epoch - 9ms/step\n",
            "Epoch 64/99\n",
            "733/733 - 6s - loss: 0.0711 - my_categorical_accuracy: 0.9787 - val_loss: 0.0754 - val_my_categorical_accuracy: 0.9743 - 6s/epoch - 9ms/step\n",
            "Epoch 65/99\n",
            "733/733 - 6s - loss: 0.0706 - my_categorical_accuracy: 0.9788 - val_loss: 0.0773 - val_my_categorical_accuracy: 0.9728 - 6s/epoch - 9ms/step\n",
            "Epoch 66/99\n",
            "733/733 - 7s - loss: 0.0701 - my_categorical_accuracy: 0.9789 - val_loss: 0.0703 - val_my_categorical_accuracy: 0.9790 - 7s/epoch - 9ms/step\n",
            "Epoch 67/99\n",
            "733/733 - 6s - loss: 0.0695 - my_categorical_accuracy: 0.9791 - val_loss: 0.0731 - val_my_categorical_accuracy: 0.9759 - 6s/epoch - 9ms/step\n",
            "Epoch 68/99\n",
            "733/733 - 7s - loss: 0.0691 - my_categorical_accuracy: 0.9791 - val_loss: 0.0707 - val_my_categorical_accuracy: 0.9778 - 7s/epoch - 9ms/step\n",
            "Epoch 69/99\n",
            "733/733 - 6s - loss: 0.0685 - my_categorical_accuracy: 0.9792 - val_loss: 0.0716 - val_my_categorical_accuracy: 0.9765 - 6s/epoch - 9ms/step\n",
            "Epoch 70/99\n",
            "733/733 - 7s - loss: 0.0683 - my_categorical_accuracy: 0.9791 - val_loss: 0.0707 - val_my_categorical_accuracy: 0.9765 - 7s/epoch - 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a4037e3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_SRQhd93Qf_W",
        "93Bz50lEQWpN",
        "d1sXdTaZQ5NI",
        "cMb0itb9UOQ2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}